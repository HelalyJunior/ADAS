{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63a4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1556ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(path,hsv=False,hls=False):\n",
    "    images=[]; Paths=[]\n",
    "    for file in os.listdir(path):\n",
    "        Paths.append(file)\n",
    "        img = cv2.imread(os.path.join(path,file))     \n",
    "        images.append(img)\n",
    "    return np.array(images),Paths\n",
    "\n",
    "def filter_color(image,min,max):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, min, max)\n",
    "    masked = cv2.bitwise_and(hsv, hsv, mask=cv2.bitwise_not(mask))\n",
    "    reconstructed = cv2.cvtColor(masked, cv2.COLOR_HSV2BGR)\n",
    "    return reconstructed\n",
    "\n",
    "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [0, 0, 0], thickness=tf, lineType=cv2.LINE_AA)\n",
    "        \n",
    "def get_roi(img):\n",
    "    img[:,:img.shape[1]//3]=0;img[:,2*(img.shape[1]//3):]=0\n",
    "    return img\n",
    "\n",
    "def get_traffic_lights_rois(hsv):\n",
    "    top=hsv[:hsv.shape[0]//3]\n",
    "    middle=hsv[hsv.shape[0]//3:2*(hsv.shape[0]//3)]\n",
    "    bottom=hsv[2*(hsv.shape[0]//3):]\n",
    "    return top,middle,bottom\n",
    "\n",
    "def get_bounding_box_area(det):\n",
    "    return (int(det[2])-int(det[0]))*int((det[3])-int(det[1]))\n",
    "\n",
    "def bgr_to_hsv(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "def crop_to_detection(hsv,det):\n",
    "    start_point = int(det[0]),int(det[1])\n",
    "    end_point = int(det[2]),int(det[3])\n",
    "    hsv=hsv[start_point[1]:end_point[1],start_point[0]:end_point[0]]\n",
    "    return hsv\n",
    "\n",
    "def get_mask(img,mini,maxi):\n",
    "    return cv2.inRange(img,mini,maxi)\n",
    "\n",
    "def count_extracted_colored_pixels(mask):\n",
    "    return cv2.countNonZero(mask)\n",
    "    \n",
    "def get_label(red,green,threshold):\n",
    "    maxi = max(red,green)\n",
    "    if maxi<threshold:\n",
    "        name=\"skip\"\n",
    "    else:\n",
    "        name = \"red\" if red>green else \"green\"\n",
    "    return name\n",
    "\n",
    "def save_img(path,img):\n",
    "    cv2.imwrite(path,img)\n",
    "    \n",
    "def load_model():\n",
    "    return torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "def detect(model,img,name,save):\n",
    "    \n",
    "    cpy=img.copy()\n",
    "    \n",
    "    ## is red ? \n",
    "    is_red = False\n",
    "\n",
    "    #### REMOVE THE LEFT AND RIGHT QUARTERS ####\n",
    "    img = get_roi(img)\n",
    "    \n",
    "    save_img(f'output2/{name}.png',img)\n",
    "\n",
    "    detections = model(img).pred[0]\n",
    "    for det in detections:\n",
    "        area = get_bounding_box_area(det)\n",
    "        *xyxy, conf, cls = det\n",
    "\n",
    "        #### ONLY HANDLE TRAFFIC LIGHTS AND NEGELCT SMALL BOUNDING BOXES ####\n",
    "        if cls != 9 or area<500:\n",
    "            continue\n",
    "\n",
    "        hsv = bgr_to_hsv(img)\n",
    "\n",
    "        ##### CROP WHOLE IMAGE TO DETECTION ####\n",
    "        hsv = crop_to_detection(hsv,det)\n",
    "\n",
    "        ################# TRAFFIC LIGHTS HADNLING ############################\n",
    "\n",
    "        #RED\n",
    "        #YELLOW\n",
    "        #GREEN\n",
    "\n",
    "        ## CROPPING THE DETECTION TO 3 PARTS ##\n",
    "        top,middle,bottom = get_traffic_lights_rois(hsv)\n",
    "\n",
    "        #### GET GREEN FROM THE BOTTOM PART ####\n",
    "        mask_green = get_mask(bottom,(40,40,40),(70,255,255))\n",
    "\n",
    "        #### GET RED FROM THE TOP PART ####\n",
    "        mask_red = get_mask(top, (0,80,20), (12,255,255))\n",
    "\n",
    "        #### COUNT NUMBER OF PIXELS ####\n",
    "        red=count_extracted_colored_pixels(mask_red)\n",
    "        green=count_extracted_colored_pixels(mask_green)\n",
    "\n",
    "        #### DECIDE ON THE LABEL ####\n",
    "        label = get_label(red,green,20)\n",
    "        \n",
    "        if label=='red':\n",
    "            is_red=True\n",
    "\n",
    "        #### PLOT THE BOX ####\n",
    "        plot_one_box(xyxy,cpy,label=label,color=(255,255,255),line_thickness=1)\n",
    "\n",
    "    #### SAVE THE DETECTIONS ####\n",
    "    if save:\n",
    "        save_img(f'output/{name}.png',cpy)\n",
    "    return cpy,is_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b67829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,_=load_images_from_folder(os.path.join('CARLA','CARLA_0.9.12','PythonAPI','examples','_out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4521d80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/helaly/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-10-26 Python-3.7.9 torch-1.12.1+cu102 CUDA:0 (NVIDIA GeForce RTX 2060, 5935MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816679a487d543b2855fa580461a10d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/14.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9634e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for img in imgs:\n",
    "    counter+=1\n",
    "    detect(model,img,counter,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c838512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
